{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mohamed tawfik\\.conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import datetime\n",
    "import sys  \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.activations import relu, tanh, elu\n",
    "from keras.optimizers import Adagrad, Adam, Nadam, SGD\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.constraints import maxnorm\n",
    "from keras import optimizers\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet as FE\n",
    "from keras.applications.mobilenet import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"MobileNet\"\n",
    "classes = 10\n",
    "weight_decay=1e-5\n",
    "lr = 1e-3\n",
    "epochs = 50\n",
    "decay = lr/epochs\n",
    "batch_size = 50\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 255.0\n",
    "    x -= 0.5\n",
    "    x *= 2.0\n",
    "    return x # x is now between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34260 images belonging to 10 classes.\n",
      "Found 4012 images belonging to 10 classes.\n",
      "Found 2581 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator_train = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False, \n",
    "    rotation_range=30, \n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=False,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.001,\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last',\n",
    "    #preprocessing_function=preprocess_input  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "data_generator_val = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False, \n",
    "    data_format='channels_last',\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "data_generator_test = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "     data_format='channels_last',\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = data_generator_train.flow_from_directory(\n",
    "    'new_data_set/training',   \n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_generator = data_generator_val.flow_from_directory(\n",
    "   'new_data_set/validation', shuffle=False,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=15\n",
    ")\n",
    "\n",
    "test_generator = data_generator_test.flow_from_directory(\n",
    "    'new_data_set/testing', shuffle=False, \n",
    "    target_size = (image_size,image_size),\n",
    "    batch_size = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training = 34260 \n",
    "num_validation = 4012 \n",
    "num_testing = 2581 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the Model \n",
    "feature_extractor= FE(input_shape=(image_size, image_size, 3), include_top=False, weights='imagenet',\n",
    "                      pooling = 'avg', classes=classes)\n",
    "\n",
    "for layer in feature_extractor.layers[:]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "classifier = feature_extractor.output\n",
    "classifier = Dropout(0.5)(classifier)\n",
    "logits1 = Dense(100, activation='relu', kernel_regularizer=keras.regularizers.l2(weight_decay)) (classifier)\n",
    "logits2 = Dense(50, activation='relu', kernel_regularizer=keras.regularizers.l2(weight_decay)) (logits1)\n",
    "logits3 = Dense(classes, activation='relu', kernel_regularizer=keras.regularizers.l2(weight_decay)) (logits2)\n",
    "probabilities = Activation('softmax') (logits3)\n",
    "    \n",
    "full_model = Model(feature_extractor.input, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add entropy to the usual logloss (it is for regularization),\n",
    "# \"Regularizing Neural Networks by Penalizing Confident Output Distributions\",\n",
    "# https://arxiv.org/abs/1701.06548\n",
    "# it reduces overfitting a little bit\n",
    "def loss(y_true, y_pred):\n",
    "    entropy = -KerasBackend.mean(KerasBackend.sum(y_pred*KerasBackend.log(y_pred), 1))\n",
    "    beta = 0.1\n",
    "    return categorical_crossentropy(y_true, y_pred) - beta*entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "                   metrics=['accuracy', top_2_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "221/685 [========>.....................] - ETA: 2:44 - loss: 1.9816 - acc: 0.3178 - top_2_accuracy: 0.5138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mohamed tawfik\\.conda\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py:2438: DecompressionBombWarning: Image size (107327830 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/685 [===============>..............] - ETA: 1:42 - loss: 1.8716 - acc: 0.3550 - top_2_accuracy: 0.5521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mohamed tawfik\\.conda\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py:2438: DecompressionBombWarning: Image size (99962094 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 246s 360ms/step - loss: 1.7589 - acc: 0.3966 - top_2_accuracy: 0.5921 - val_loss: 1.4903 - val_acc: 0.5146 - val_top_2_accuracy: 0.6782\n",
      "Epoch 2/50\n",
      "685/685 [==============================] - 239s 348ms/step - loss: 1.4795 - acc: 0.5076 - top_2_accuracy: 0.6830 - val_loss: 1.3525 - val_acc: 0.5539 - val_top_2_accuracy: 0.7215\n",
      "Epoch 3/50\n",
      "685/685 [==============================] - 238s 347ms/step - loss: 1.3694 - acc: 0.5396 - top_2_accuracy: 0.7142 - val_loss: 1.2557 - val_acc: 0.5789 - val_top_2_accuracy: 0.7463\n",
      "Epoch 4/50\n",
      "685/685 [==============================] - 237s 347ms/step - loss: 1.3262 - acc: 0.5493 - top_2_accuracy: 0.7286 - val_loss: 1.2631 - val_acc: 0.5804 - val_top_2_accuracy: 0.7461\n",
      "Epoch 5/50\n",
      "685/685 [==============================] - 237s 346ms/step - loss: 1.2894 - acc: 0.5624 - top_2_accuracy: 0.7361 - val_loss: 1.1974 - val_acc: 0.5994 - val_top_2_accuracy: 0.7573\n",
      "Epoch 6/50\n",
      "685/685 [==============================] - 237s 346ms/step - loss: 1.2661 - acc: 0.5680 - top_2_accuracy: 0.7449 - val_loss: 1.1841 - val_acc: 0.6032 - val_top_2_accuracy: 0.7686\n",
      "Epoch 7/50\n",
      "685/685 [==============================] - 241s 352ms/step - loss: 1.2479 - acc: 0.5726 - top_2_accuracy: 0.7477 - val_loss: 1.1842 - val_acc: 0.6032 - val_top_2_accuracy: 0.7676\n",
      "Epoch 8/50\n",
      "685/685 [==============================] - 238s 348ms/step - loss: 1.2329 - acc: 0.5785 - top_2_accuracy: 0.7547 - val_loss: 1.1399 - val_acc: 0.6127 - val_top_2_accuracy: 0.7838\n",
      "Epoch 9/50\n",
      "685/685 [==============================] - 238s 347ms/step - loss: 1.2249 - acc: 0.5805 - top_2_accuracy: 0.7562 - val_loss: 1.1794 - val_acc: 0.6045 - val_top_2_accuracy: 0.7741\n",
      "Epoch 10/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.2142 - acc: 0.5813 - top_2_accuracy: 0.7603 - val_loss: 1.1097 - val_acc: 0.6230 - val_top_2_accuracy: 0.7918\n",
      "Epoch 11/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.2089 - acc: 0.5826 - top_2_accuracy: 0.7658 - val_loss: 1.1196 - val_acc: 0.6202 - val_top_2_accuracy: 0.7926\n",
      "Epoch 12/50\n",
      "685/685 [==============================] - 238s 347ms/step - loss: 1.1974 - acc: 0.5848 - top_2_accuracy: 0.7668 - val_loss: 1.1154 - val_acc: 0.6205 - val_top_2_accuracy: 0.7963\n",
      "Epoch 13/50\n",
      "685/685 [==============================] - 238s 348ms/step - loss: 1.1835 - acc: 0.5924 - top_2_accuracy: 0.7758 - val_loss: 1.0971 - val_acc: 0.6252 - val_top_2_accuracy: 0.7991\n",
      "Epoch 14/50\n",
      "685/685 [==============================] - 238s 348ms/step - loss: 1.1898 - acc: 0.5852 - top_2_accuracy: 0.7707 - val_loss: 1.1406 - val_acc: 0.6112 - val_top_2_accuracy: 0.7921\n",
      "Epoch 15/50\n",
      "685/685 [==============================] - 238s 348ms/step - loss: 1.1804 - acc: 0.5913 - top_2_accuracy: 0.7730 - val_loss: 1.1100 - val_acc: 0.6207 - val_top_2_accuracy: 0.7981\n",
      "Epoch 16/50\n",
      "685/685 [==============================] - 238s 348ms/step - loss: 1.1727 - acc: 0.5959 - top_2_accuracy: 0.7784 - val_loss: 1.1310 - val_acc: 0.6135 - val_top_2_accuracy: 0.7863\n",
      "Epoch 17/50\n",
      "685/685 [==============================] - 238s 348ms/step - loss: 1.1699 - acc: 0.5942 - top_2_accuracy: 0.7799 - val_loss: 1.0734 - val_acc: 0.6317 - val_top_2_accuracy: 0.8164\n",
      "Epoch 18/50\n",
      "685/685 [==============================] - 238s 348ms/step - loss: 1.1603 - acc: 0.6012 - top_2_accuracy: 0.7791 - val_loss: 1.0857 - val_acc: 0.6240 - val_top_2_accuracy: 0.8059\n",
      "Epoch 19/50\n",
      "685/685 [==============================] - 239s 348ms/step - loss: 1.1591 - acc: 0.5996 - top_2_accuracy: 0.7793 - val_loss: 1.0995 - val_acc: 0.6200 - val_top_2_accuracy: 0.8104\n",
      "Epoch 20/50\n",
      "685/685 [==============================] - 239s 348ms/step - loss: 1.1565 - acc: 0.5983 - top_2_accuracy: 0.7816 - val_loss: 1.0735 - val_acc: 0.6250 - val_top_2_accuracy: 0.8039\n",
      "Epoch 21/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1581 - acc: 0.5988 - top_2_accuracy: 0.7818 - val_loss: 1.0885 - val_acc: 0.6220 - val_top_2_accuracy: 0.8031\n",
      "Epoch 22/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1456 - acc: 0.6010 - top_2_accuracy: 0.7864 - val_loss: 1.0968 - val_acc: 0.6172 - val_top_2_accuracy: 0.7976\n",
      "Epoch 23/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1476 - acc: 0.5971 - top_2_accuracy: 0.7840 - val_loss: 1.0553 - val_acc: 0.6305 - val_top_2_accuracy: 0.8069\n",
      "Epoch 24/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1422 - acc: 0.6029 - top_2_accuracy: 0.7856 - val_loss: 1.0546 - val_acc: 0.6355 - val_top_2_accuracy: 0.8141\n",
      "Epoch 25/50\n",
      "685/685 [==============================] - 239s 348ms/step - loss: 1.1398 - acc: 0.6005 - top_2_accuracy: 0.7870 - val_loss: 1.0633 - val_acc: 0.6335 - val_top_2_accuracy: 0.8084\n",
      "Epoch 26/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1334 - acc: 0.6049 - top_2_accuracy: 0.7901 - val_loss: 1.0848 - val_acc: 0.6297 - val_top_2_accuracy: 0.8139\n",
      "Epoch 27/50\n",
      "685/685 [==============================] - 239s 348ms/step - loss: 1.1262 - acc: 0.6099 - top_2_accuracy: 0.7911 - val_loss: 1.0672 - val_acc: 0.6322 - val_top_2_accuracy: 0.7998\n",
      "Epoch 28/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1396 - acc: 0.6014 - top_2_accuracy: 0.7876 - val_loss: 1.0546 - val_acc: 0.6362 - val_top_2_accuracy: 0.8131\n",
      "Epoch 29/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1329 - acc: 0.6048 - top_2_accuracy: 0.7909 - val_loss: 1.0599 - val_acc: 0.6277 - val_top_2_accuracy: 0.8156\n",
      "Epoch 30/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.1303 - acc: 0.6056 - top_2_accuracy: 0.7929 - val_loss: 1.0309 - val_acc: 0.6427 - val_top_2_accuracy: 0.8136\n",
      "Epoch 31/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.1224 - acc: 0.6083 - top_2_accuracy: 0.7940 - val_loss: 1.0562 - val_acc: 0.6285 - val_top_2_accuracy: 0.8131\n",
      "Epoch 32/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.1226 - acc: 0.6089 - top_2_accuracy: 0.7933 - val_loss: 1.0505 - val_acc: 0.6367 - val_top_2_accuracy: 0.8069\n",
      "Epoch 33/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1212 - acc: 0.6098 - top_2_accuracy: 0.7964 - val_loss: 1.0418 - val_acc: 0.6367 - val_top_2_accuracy: 0.8156\n",
      "Epoch 34/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.1083 - acc: 0.6157 - top_2_accuracy: 0.7975 - val_loss: 1.0297 - val_acc: 0.6370 - val_top_2_accuracy: 0.8226\n",
      "Epoch 35/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1106 - acc: 0.6103 - top_2_accuracy: 0.7981 - val_loss: 1.0479 - val_acc: 0.6372 - val_top_2_accuracy: 0.8194\n",
      "Epoch 36/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1061 - acc: 0.6139 - top_2_accuracy: 0.7983 - val_loss: 1.0262 - val_acc: 0.6392 - val_top_2_accuracy: 0.8159\n",
      "Epoch 37/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.1125 - acc: 0.6132 - top_2_accuracy: 0.7978 - val_loss: 1.0323 - val_acc: 0.6392 - val_top_2_accuracy: 0.8139\n",
      "Epoch 38/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.1083 - acc: 0.6125 - top_2_accuracy: 0.7980 - val_loss: 1.0650 - val_acc: 0.6292 - val_top_2_accuracy: 0.8066\n",
      "Epoch 39/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.1064 - acc: 0.6133 - top_2_accuracy: 0.7979 - val_loss: 1.0361 - val_acc: 0.6392 - val_top_2_accuracy: 0.8171\n",
      "Epoch 40/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.0934 - acc: 0.6201 - top_2_accuracy: 0.8049 - val_loss: 1.0404 - val_acc: 0.6417 - val_top_2_accuracy: 0.8144\n",
      "Epoch 41/50\n",
      "685/685 [==============================] - 239s 350ms/step - loss: 1.0982 - acc: 0.6171 - top_2_accuracy: 0.7987 - val_loss: 1.0381 - val_acc: 0.6352 - val_top_2_accuracy: 0.8116\n",
      "Epoch 42/50\n",
      "685/685 [==============================] - 239s 349ms/step - loss: 1.0928 - acc: 0.6164 - top_2_accuracy: 0.8034 - val_loss: 1.0239 - val_acc: 0.6375 - val_top_2_accuracy: 0.8201\n",
      "Epoch 43/50\n",
      "685/685 [==============================] - 239s 348ms/step - loss: 1.0937 - acc: 0.6182 - top_2_accuracy: 0.8008 - val_loss: 1.0336 - val_acc: 0.6397 - val_top_2_accuracy: 0.8169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.0883 - acc: 0.6191 - top_2_accuracy: 0.8051 - val_loss: 1.0235 - val_acc: 0.6362 - val_top_2_accuracy: 0.8236\n",
      "Epoch 45/50\n",
      "685/685 [==============================] - 237s 346ms/step - loss: 1.0897 - acc: 0.6170 - top_2_accuracy: 0.8015 - val_loss: 1.0466 - val_acc: 0.6322 - val_top_2_accuracy: 0.8171\n",
      "Epoch 46/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.0864 - acc: 0.6191 - top_2_accuracy: 0.8059 - val_loss: 1.0257 - val_acc: 0.6337 - val_top_2_accuracy: 0.8284\n",
      "Epoch 47/50\n",
      "685/685 [==============================] - 239s 348ms/step - loss: 1.0897 - acc: 0.6208 - top_2_accuracy: 0.8037 - val_loss: 1.0235 - val_acc: 0.6410 - val_top_2_accuracy: 0.8239\n",
      "Epoch 48/50\n",
      "685/685 [==============================] - 237s 346ms/step - loss: 1.0927 - acc: 0.6187 - top_2_accuracy: 0.8022 - val_loss: 1.0308 - val_acc: 0.6395 - val_top_2_accuracy: 0.8204\n",
      "Epoch 49/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.0876 - acc: 0.6215 - top_2_accuracy: 0.8058 - val_loss: 1.0203 - val_acc: 0.6367 - val_top_2_accuracy: 0.8254\n",
      "Epoch 50/50\n",
      "685/685 [==============================] - 240s 350ms/step - loss: 1.0765 - acc: 0.6220 - top_2_accuracy: 0.8047 - val_loss: 1.0341 - val_acc: 0.6377 - val_top_2_accuracy: 0.8159\n"
     ]
    }
   ],
   "source": [
    "check_point = ModelCheckpoint(\"my_best_weights_\" + name + \"_training.hdf5\", monitor = \"val_acc\", save_best_only = True, period = 1)\n",
    "history = full_model.fit_generator(  train_generator,\n",
    "                                #steps_per_epoch= 10,\n",
    "                                steps_per_epoch= num_training // batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data=val_generator,\n",
    "                                   validation_steps= num_validation // 15,\n",
    "                                verbose=1,\n",
    "                                workers=8, \n",
    "                                callbacks=[check_point],\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.load_weights(\"my_best_weights_MobileNet_training.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save(name + \"_10_classes_training.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1\n",
      "2 conv1_bn\n",
      "3 conv1_relu\n",
      "4 conv_dw_1\n",
      "5 conv_dw_1_bn\n",
      "6 conv_dw_1_relu\n",
      "7 conv_pw_1\n",
      "8 conv_pw_1_bn\n",
      "9 conv_pw_1_relu\n",
      "10 conv_dw_2\n",
      "11 conv_dw_2_bn\n",
      "12 conv_dw_2_relu\n",
      "13 conv_pw_2\n",
      "14 conv_pw_2_bn\n",
      "15 conv_pw_2_relu\n",
      "16 conv_dw_3\n",
      "17 conv_dw_3_bn\n",
      "18 conv_dw_3_relu\n",
      "19 conv_pw_3\n",
      "20 conv_pw_3_bn\n",
      "21 conv_pw_3_relu\n",
      "22 conv_dw_4\n",
      "23 conv_dw_4_bn\n",
      "24 conv_dw_4_relu\n",
      "25 conv_pw_4\n",
      "26 conv_pw_4_bn\n",
      "27 conv_pw_4_relu\n",
      "28 conv_dw_5\n",
      "29 conv_dw_5_bn\n",
      "30 conv_dw_5_relu\n",
      "31 conv_pw_5\n",
      "32 conv_pw_5_bn\n",
      "33 conv_pw_5_relu\n",
      "34 conv_dw_6\n",
      "35 conv_dw_6_bn\n",
      "36 conv_dw_6_relu\n",
      "37 conv_pw_6\n",
      "38 conv_pw_6_bn\n",
      "39 conv_pw_6_relu\n",
      "40 conv_dw_7\n",
      "41 conv_dw_7_bn\n",
      "42 conv_dw_7_relu\n",
      "43 conv_pw_7\n",
      "44 conv_pw_7_bn\n",
      "45 conv_pw_7_relu\n",
      "46 conv_dw_8\n",
      "47 conv_dw_8_bn\n",
      "48 conv_dw_8_relu\n",
      "49 conv_pw_8\n",
      "50 conv_pw_8_bn\n",
      "51 conv_pw_8_relu\n",
      "52 conv_dw_9\n",
      "53 conv_dw_9_bn\n",
      "54 conv_dw_9_relu\n",
      "55 conv_pw_9\n",
      "56 conv_pw_9_bn\n",
      "57 conv_pw_9_relu\n",
      "58 conv_dw_10\n",
      "59 conv_dw_10_bn\n",
      "60 conv_dw_10_relu\n",
      "61 conv_pw_10\n",
      "62 conv_pw_10_bn\n",
      "63 conv_pw_10_relu\n",
      "64 conv_dw_11\n",
      "65 conv_dw_11_bn\n",
      "66 conv_dw_11_relu\n",
      "67 conv_pw_11\n",
      "68 conv_pw_11_bn\n",
      "69 conv_pw_11_relu\n",
      "70 conv_dw_12\n",
      "71 conv_dw_12_bn\n",
      "72 conv_dw_12_relu\n",
      "73 conv_pw_12\n",
      "74 conv_pw_12_bn\n",
      "75 conv_pw_12_relu\n",
      "76 conv_dw_13\n",
      "77 conv_dw_13_bn\n",
      "78 conv_dw_13_relu\n",
      "79 conv_pw_13\n",
      "80 conv_pw_13_bn\n",
      "81 conv_pw_13_relu\n",
      "82 global_average_pooling2d_1\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(feature_extractor.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in feature_extractor.layers[:70]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in feature_extractor.layers[70:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=SGD(lr=lr/10, momentum=0.9, nesterov=True)\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "                   metrics=['accuracy', top_2_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = ModelCheckpoint(\"my_best_weights_\" + name + \"_finetuning.hdf5\", monitor = \"val_acc\", save_best_only = True, period = 1)\n",
    "history = full_model.fit_generator(  train_generator,\n",
    "                                steps_per_epoch= num_training  // batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data=val_generator,\n",
    "                                verbose=1,\n",
    "                                workers=8, \n",
    "                                callbacks=[check_point],\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save(name + \"_10_classes_finetuning.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
