{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import datetime\n",
    "import sys  \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.activations import relu, tanh, elu\n",
    "from keras.optimizers import Adagrad, Adam, Nadam, SGD\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.constraints import maxnorm\n",
    "from keras import optimizers\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    return tf.keras.applications.resnet50.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39431 images belonging to 6 classes.\n",
      "Found 4614 images belonging to 6 classes.\n",
      "Found 2078 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator_train = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False, \n",
    "    rotation_range=30, \n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=False,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.001,\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last',\n",
    "   #preprocessing_function=preprocess_input  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "data_generator_val = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False, \n",
    "     data_format='channels_last',\n",
    "  #preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "data_generator_test = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "     data_format='channels_last',\n",
    "   #preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = data_generator_train.flow_from_directory(\n",
    "    'E:/My_Dataset/Training_data',   \n",
    "    target_size=(250, 250),\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "val_generator = data_generator_val.flow_from_directory(\n",
    "    'E:/My_Dataset/Validation_data', shuffle=False,\n",
    "    target_size=(250, 250),\n",
    "    batch_size=20\n",
    ")\n",
    "\n",
    "test_generator = data_generator_test.flow_from_directory(\n",
    "    'E:/My_Dataset/Testing_data', shuffle=False, target_size = (250,250), batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 6\n",
    "weight_decay=1e-5\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "decay = lr/epochs\n",
    "\n",
    "# Constructing the Model \n",
    "feature_extractor = keras.applications.resnet50.ResNet50(input_shape=(250, 250, 3), include_top=False, weights='imagenet', pooling = 'avg', classes=classes)\n",
    "# make sure eno 3rd dimension is 3 ????\n",
    "\n",
    "\n",
    "#feature_extractor = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(250, 250, 3), pooling='avg', classes=classes)\n",
    "#feature_extractor = keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_shape=(250, 250, 3), pooling='avg', classes=classes)\n",
    "# feature_extractor = keras.applications.mobilenet.MobileNet(input_shape=(250, 250, 3), alpha=1.0, depth_multiplier=1, dropout=1e-3, include_top=False, weights='imagenet', pooling='avg', classes=classes)\n",
    "\n",
    "\n",
    "for layer in feature_extractor.layers[:]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "classifier = feature_extractor.output\n",
    "classifier = Dropout(0.5)(classifier)\n",
    "logits1 = Dense(100, activation='relu', kernel_regularizer=keras.regularizers.l2(weight_decay)) (classifier)\n",
    "logits2 = Dense(50, activation='relu', kernel_regularizer=keras.regularizers.l2(weight_decay)) (logits1)\n",
    "logits3 = Dense(classes, activation='relu', kernel_regularizer=keras.regularizers.l2(weight_decay)) (logits2)\n",
    "probabilities = Activation('softmax') (logits3)\n",
    "    \n",
    "full_model = Model(feature_extractor.input, probabilities)\n",
    "\n",
    "nadam = Nadam(lr=lr,beta_1=0.9, beta_2 = 0.999, epsilon = 1e-8, schedule_decay=decay)\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "262/394 [==================>...........] - ETA: 5:38 - loss: 1.4968 - acc: 0.4078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4718592 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\Lenovo\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 787528 bytes but only got 5533. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\Lenovo\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7281180688 bytes but only got 0. Skipping tag 8\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/394 [===================>..........] - ETA: 5:09 - loss: 1.4940 - acc: 0.4092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 787528 bytes but only got 5401. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 1206s 3s/step - loss: 1.4726 - acc: 0.4202 - val_loss: 1.4796 - val_acc: 0.4330\n",
      "Epoch 2/20\n",
      "394/394 [==============================] - 3642s 9s/step - loss: 1.3760 - acc: 0.4797 - val_loss: 1.3834 - val_acc: 0.4933\n",
      "Epoch 3/20\n",
      "394/394 [==============================] - 1567s 4s/step - loss: 1.2824 - acc: 0.5195 - val_loss: 1.2128 - val_acc: 0.5262\n",
      "Epoch 4/20\n",
      "213/394 [===============>..............] - ETA: 12:00 - loss: 1.1355 - acc: 0.5659"
     ]
    }
   ],
   "source": [
    "check_point = ModelCheckpoint(\"my_best_weights.hdf5\", monitor = \"val_acc\", save_best_only = True, period = 1)\n",
    "batch_size = 100\n",
    "history = full_model.fit_generator(  train_generator,\n",
    "                                steps_per_epoch= 39431 // batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data=val_generator,\n",
    "                                verbose=1,\n",
    "                                workers=8, \n",
    "                                callbacks=[check_point],\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
